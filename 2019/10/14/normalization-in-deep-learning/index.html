<!DOCTYPE html>
<html  lang="en">
<head>
    <meta charset="utf-8" />

<meta name="generator" content="Hexo 3.9.0" />

<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1" />

<title>Normalization in Deep Learning - DeepBlog</title>


    <meta name="description" content="Normalization refers to a process that makes something more normal or regular.   In statistics, normalization means adjusting values measured on different scales to a common scale, or adjustments to">
<meta name="keywords" content="Deep Learning, Machine Learning, NLP">
<meta property="og:type" content="article">
<meta property="og:title" content="Normalization in Deep Learning">
<meta property="og:url" content="http://sxiazr.github.io/2019/10/14/normalization-in-deep-learning/index.html">
<meta property="og:site_name" content="DeepBlog">
<meta property="og:description" content="Normalization refers to a process that makes something more normal or regular.   In statistics, normalization means adjusting values measured on different scales to a common scale, or adjustments to">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://sxiazr.github.io/images/og_image.png">
<meta property="og:updated_time" content="2019-10-16T09:59:41.414Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Normalization in Deep Learning">
<meta name="twitter:description" content="Normalization refers to a process that makes something more normal or regular.   In statistics, normalization means adjusting values measured on different scales to a common scale, or adjustments to">
<meta name="twitter:image" content="http://sxiazr.github.io/images/og_image.png">







<link rel="icon" href="/images/favicon.svg">


<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bulma@0.7.2/css/bulma.css">
<link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.4.1/css/all.css">
<link rel="stylesheet" href="https://fonts.googleapis.com/css?family=Ubuntu:400,600|Source+Code+Pro">
<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css">


    
    
    
    <style>body>.footer,body>.navbar,body>.section{opacity:0}</style>
    

    
    
    
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css">
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css">
    

    
    

<link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.css">


    
    
    
    

<link rel="stylesheet" href="/css/back-to-top.css">


    
    

    
    
    
    

    
    
<link rel="stylesheet" href="/css/progressbar.css">
<script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script>

    
    
    
        <script async="" src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    

    


<link rel="stylesheet" href="/css/style.css">

</head>
<body class="is-3-column">
    <nav class="navbar navbar-main">
    <div class="container">
        <div class="navbar-brand is-flex-center">
            <a class="navbar-item navbar-logo" href="/">
            
                <img src="/images/logo.svg" alt="Normalization in Deep Learning" height="28">
            
            </a>
        </div>
        <div class="navbar-menu">
            
            <div class="navbar-start">
                
                <a class="navbar-item"
                href="/">Home</a>
                
                <a class="navbar-item"
                href="/archives">Archives</a>
                
                <a class="navbar-item"
                href="/categories">Categories</a>
                
                <a class="navbar-item"
                href="/tags">Tags</a>
                
                <a class="navbar-item"
                href="/about">About</a>
                
            </div>
            
            <div class="navbar-end">
                
                    
                    
                    <a class="navbar-item" target="_blank" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                    
                
                
                
                <a class="navbar-item search" title="Search" href="javascript:;">
                    <i class="fas fa-search"></i>
                </a>
                
            </div>
        </div>
    </div>
</nav>
    
    <section class="section">
        <div class="container">
            <div class="columns">
                <div class="column is-8-tablet is-8-desktop is-9-widescreen has-order-2 column-main"><div class="card">
    
    <div class="card-content article ">
        
        <div class="level article-meta is-size-7 is-uppercase is-mobile is-overflow-x-auto">
            <div class="level-left">
                <time class="level-item has-text-grey" datetime="2019-10-14T16:00:00.000Z">2019-10-15</time>
                
                
                <span class="level-item has-text-grey">
                    
                    
                    11 minutes read (About 1634 words)
                </span>
                
                
                <span class="level-item has-text-grey" id="busuanzi_container_page_pv">
                    <i class="far fa-eye"></i>
                    <span id="busuanzi_value_page_pv">0</span> visits
                </span>
                
            </div>
        </div>
        
        <h1 class="title is-size-3 is-size-4-mobile has-text-weight-normal">
            
                Normalization in Deep Learning
            
        </h1>
        <div class="content">
            <blockquote>
<p><a href="https://en.wikipedia.org/wiki/Normalization_(statistics)" target="_blank" rel="noopener">Normalization</a> refers to a process that makes something more normal or regular. </p>
</blockquote>
<p>In statistics, normalization means adjusting values measured on different scales to a common scale, or adjustments to bring the entire probability distributions of adjusted values into alignment. Normalization in deep learning can make the model to train efficiently.</p>
<h1 id="Why-does-Normalization-work"><a href="#Why-does-Normalization-work" class="headerlink" title="Why does Normalization work?"></a>Why does Normalization work?</h1><h2 id="Intuition-1-Input-Normalization-frac-X-mu-sigma"><a href="#Intuition-1-Input-Normalization-frac-X-mu-sigma" class="headerlink" title="Intuition 1: Input Normalization $\frac{X - \mu}{\sigma}$"></a>Intuition 1: Input Normalization $\frac{X - \mu}{\sigma}$</h2><blockquote>
<p>Make training less sensitive to the scale of features.</p>
</blockquote>
<p>After optimization, the feature with a large scale will always be weighted with a small value ($\omega_{small}$), and vise versa ($\omega_{large}$). Because of the large scale of the feature, a tiny change in the small weight ($\omega_{small}$) will change the prediction by a lot compared to the same change in the large weight ($\omega_{large}$). It means that setting $\omega_{small}$ correctly might dominate the optimization process and the feature with a large scale is of more importance which actually makes no sense.</p>
<blockquote>
<p>Make optimization well-conditioned.</p>
</blockquote>
<p>The rough intuition is that the cost function will be more round and easier to optimize when features are all on similar scales. </p>
<a id="more"></a>
<p>Cost function of the unnormalized features can be a very elongated bowl, whereas if we normalize the features, then the cost function will look more symmetric. Having an elongated cost function, we might have to use a very small learning rate and gradient descent might need a lot of steps to oscillate back and forth before it finally gets to the minimum. If we have more spherical contours, then gradient descent can pretty much go straight to the minimum and we can take much larger steps with gradient descent without much oscillation.</p>
<p align="center">
  <img src="./why-normalize-inputs.jpg" alt="Why normalize inputs" width="500px">
</p>

<h2 id="Intuition-2-Covariate-Shift"><a href="#Intuition-2-Covariate-Shift" class="headerlink" title="Intuition 2: Covariate Shift"></a>Intuition 2: Covariate Shift</h2><blockquote>
<p>Covariate shift refers to the problem that the distribution of the input values changes, but the concept (model) being learned remains stationary.</p>
</blockquote>
<p>In deep learning, the basic idea behind normalization is to limit the covariate shift, which allows the model to learn on a more stable distribution, and would thus accelerate the training of the network.</p>
<h1 id="Batch-Normalization"><a href="#Batch-Normalization" class="headerlink" title="Batch Normalization"></a>Batch Normalization</h1><p>In deep learning, we are particularly concerned with the change in the distribution of the inputs to the hidden nodes within a network. A neural network changes the weights of each layer over the training, which means that the activations of each layer change as well. Since the activations of a previous layer are the inputs of the next layer, each layer in the neural network is faced with a situation where the input distribution changes with each step (<strong>covariate shift</strong>). </p>
<h2 id="Batch-Normalization-at-Training-Time"><a href="#Batch-Normalization-at-Training-Time" class="headerlink" title="Batch Normalization at Training Time"></a>Batch Normalization at Training Time</h2><blockquote>
<p>What <a href="(https://arxiv.org/pdf/1502.03167.pdf">batch normalization</a> does is, especially from the perspective of the later layers of the neural network, it limits the earlier layers to not get to shift around much, by restricting them to have the same mean and variance.  It weakens the coupling between what the early layers and the later layers.</p>
</blockquote>
<p>For a layer of the network with d-dimensional input, $x = (x^{(1)},…,x^{(d)})$, each dimension is then normalized separately as following:</p>
<p>$$\hat{x}_i^{(k)} = \frac{x_i^{(k)}-\mu_B^{(k)}}{\sqrt{\sigma_B^{(k)^2}+\epsilon}}$$where $\mu_B^{(k)}$ and $\sigma_B^{(k)^2}$ are the per-dimension mean and variance, respectively. $\epsilon$ is added in the denominator for numerical stability and is an arbitrarily small constant. </p>
<p>The resulting normalized $\hat{x}^{(k)}$ have zero mean and unit variance, to restore the representation power of the network or better take advantage of the nonlinearity (if activations are normalized), a transformation step then follows as:<br>$$y_i^{(k)} = \gamma^{(k)} \hat{x}_{i}^{(k)} +\beta^{(k)}$$where the parameters $\gamma^{(k)}$and $\beta^{(k)}$ are subsequently learnt in the optimization process and can convert the mean and variance to any value that the network desires.</p>
<p>Formally, the transform $BN_{\gamma,\beta}: x_{1…m} \rightarrow y_{1…m}$ is denoted as the Batch Normalizing Transform.</p>
<blockquote>
<p>There are some debates in deep learning about whether we<br>should normalize the value before the activation function or after it. </p>
</blockquote>
<p>In practice, normalizing before the activation function is done much more often.</p>
<blockquote>
<p><a href="https://en.wikipedia.org/wiki/Regularization_(mathematics)" target="_blank" rel="noopener">Regularization</a> can be motivated as a technique to improve the generalizability of a learned model. Batch normalization has a slight regularization effect.  </p>
</blockquote>
<p>The mean and variance are a little bit noisy because they are estimated on a mini-batch. Similar to dropout, batch normalization adds small noise to the hidden layers and therefore has a very slight regularization effect.</p>
<p>We don’t particularly use to batch normalization as a regularization but use it as a way to speed up learning.</p>
<h2 id="Batch-Normalization-at-Test-Time"><a href="#Batch-Normalization-at-Test-Time" class="headerlink" title="Batch Normalization at Test Time"></a>Batch Normalization at Test Time</h2><blockquote>
<p>At the test time, we use the $\gamma$ and $\beta$ learned from training, the $\mu$ and $\sigma^2$ are estimated from the training set.</p>
</blockquote>
<p>Running the whole training set to get $\mu$ and $\sigma^2$ could be memory-consuming. So we keep a running average of the $\mu$ and $\sigma^2$ for each layer as we train the neural network across different mini-batches to get an estimation of them. </p>
<blockquote>
<p>In practice, the moving average people usually use here is exponentially weighted average.</p>
</blockquote>
<p>An <strong>exponential moving average (EMA)</strong>, also known as an exponentially weighted moving average (EWMA), is a first-order filter that applies weighting factors which decrease exponentially.</p>
<p>The EMA for a series $Y$ is calculated recursively:</p>
<p>$$S_t = \begin{cases}<br> \alpha \cdot Y_1, &amp; t = 1 \\<br> \alpha \cdot Y_t + (1 - \alpha) \cdot S_{t-1}, &amp; t &gt; 1<br>\end{cases}$$<br>Where:</p>
<ul>
<li>$\alpha$ represents the degree of weighting decrease, a constant smoothing factor between 0 and 1. </li>
<li>$Y_t$ and $S_t$ are the values at a time period $t$ respectively.</li>
</ul>
<p>This formula can also be expressed in technical analysis terms as follows:</p>
<ul>
<li>How the EMA steps towards the latest datum point:<br>$$\text{EMA}_\text{today} = \text{EMA}_\text{yesterday} + \alpha \left[\text{price}_\text{today} - \text{EMA}_\text{yesterday}\right]$$</li>
<li>How the weighting factor on each data point $p_1$, $p_2$, etc., decreases exponentially by expanding out $\text{EMA}_\text{yesterday}$ :<br>$$\begin{split}<br>\text{EMA}_\text{today}<br>= &amp; { \alpha \left[p_1 + (1 - \alpha) p_2 + (1 - \alpha)^2 p_3 + (1 - \alpha)^3 p_4 + \cdots \right] } \\<br>= &amp;\frac{p_1 + (1 - \alpha) p_2 + (1 - \alpha)^2 p_3 + (1 - \alpha)^3 p_4 + \cdots}{1 + (1 - \alpha) + (1 - \alpha)^2 + (1 - \alpha)^3 + \cdots}<br>\end{split}$$since $1/\alpha = 1 + (1 - \alpha) + (1 - \alpha)^2 + \cdots$ (<strong>weighted average</strong>).</li>
</ul>
<p>A couple of things about choosing $\alpha$:</p>
<ul>
<li>A higher $\alpha$ discounts older observations faster so that the EMA will adapt more quickly to the current changes.</li>
<li>When compute EMA,  we can think of  $S_t$ as approximately averaging over $\frac{1}{\alpha}$ number of data. So with a low value of $\alpha$, the EMA is much <strong>smoother</strong> and also has more <strong>latency</strong>.  (Always set to <strong>0.1</strong> in deep learning)</li>
</ul>
<blockquote>
<p>Bias correction is a technical modification that makes EMA estimate more accurate, especially during its initial phase.</p>
</blockquote>
<p>The EMA is very low when the iteration just starts off and we will get a much lower value that is not a very good estimate of the first data. In order to fix the problem, we could instead of taking $S_t$, take $\frac{S_t}{1-(1-a)^t}$, namely bias correction. It will make the EMA larger when $t$ is small and make almost no difference when $t$ is large enough.</p>
<h1 id="Weight-Normalization"><a href="#Weight-Normalization" class="headerlink" title="Weight Normalization"></a>Weight Normalization</h1><h2 id="The-Limitations-of-Batch-Normalization"><a href="#The-Limitations-of-Batch-Normalization" class="headerlink" title="The Limitations of Batch Normalization"></a>The Limitations of Batch Normalization</h2><p>The key limitation of batch normalization is that it is <strong>dependent on the mini-batch</strong>.</p>
<blockquote>
<p>It puts a  <strong>lower limit on the batch size</strong>.</p>
</blockquote>
<p>Ideally, we want to use the <strong>global</strong> mean and variance to normalize the inputs to a layer. However, it’s too costly and the mean and variance are simply estimates on mini-batch, which means that they contain a certain amount of noises.</p>
<p>Smaller mini-batch sizes increase the variance of these estimates. It can be a problem in settings such as online learning and reinforcement learning which is highly sensitive to noise.</p>
<blockquote>
<p>It is <strong>difficult to apply to recurrent connections</strong> in recurrent neural network.</p>
</blockquote>
<p>In a recurrent neural network, the recurrent activations of each time-step will have different statistics. This means that we have to fit a separate batch normalization layer for each time-step and it forces us to store the statistics for each time-step during training.</p>
<h2 id="Theory-of-Weight-Normalization"><a href="#Theory-of-Weight-Normalization" class="headerlink" title="Theory of Weight Normalization"></a>Theory of Weight Normalization</h2><blockquote>
<p>What <a href="https://arxiv.org/pdf/1602.07868.pdf" target="_blank" rel="noopener">weight normalization</a> does is it <strong>separates the norm of the weight vector from its direction</strong>. </p>
</blockquote>
<p>In an effort to speed up the convergence of optimization procedure, it proposes to reparameterize each weight vector $\omega$ in terms of a parameter vector $\boldsymbol{v}$ and a scalar parameter $g$ in the following way:</p>
<p>$$\omega = \frac{g}{||\boldsymbol{v}||}\boldsymbol{v}$$It then optimizes both$\boldsymbol{v}$ and $g$ using gradient descent. This reparameterization has the effect of fixing the Euclidean norm of the weight vector $\omega$: we now have $||\omega||=g$, independent of the parameters $\boldsymbol{v}$. We, therefore, call this reparameterization weight normalization.</p>
<h1 id="Layer-Normalization"><a href="#Layer-Normalization" class="headerlink" title="Layer Normalization"></a>Layer Normalization</h1><h2 id="Theory-of-Layer-Normalization"><a href="#Theory-of-Layer-Normalization" class="headerlink" title="Theory of Layer Normalization"></a>Theory of Layer Normalization</h2><blockquote>
<p>The key feature of <a href="https://arxiv.org/pdf/1607.06450.pdf" target="_blank" rel="noopener">layer normalization</a> is that it <strong>normalizes the inputs across the features</strong>.</p>
</blockquote>
<p>The equations of layer normalization and batch normalization are similar:$$\hat{x}_i^{(k)} = \frac{x_i^{(k)}-\mu_L}{\sqrt{\sigma_L^2+\epsilon}}$$where $\mu_L$ and $\sigma_L^2$ are the mean and variance across the features, respectively. </p>
<h1 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h1><p><a href="https://www.quora.com/Why-do-we-normalize-the-data" target="_blank" rel="noopener">Quora: Why do we normalize the data</a><br><a href="https://www.coursera.org/specializations/deep-learning" target="_blank" rel="noopener">Coursera: Deep Learning Specialization</a><br><a href="https://mlexplained.com/2018/01/10/an-intuitive-explanation-of-why-batch-normalization-really-works-normalization-in-deep-learning-part-1/" target="_blank" rel="noopener">Blog: An Intuitive Explanation of Why Batch Normalization Really Works</a><br><a href="https://mlexplained.com/2018/01/13/weight-normalization-and-layer-normalization-explained-normalization-in-deep-learning-part-2/" target="_blank" rel="noopener">Blog: Weight Normalization and Layer Normalization Explained</a><br><a href="https://mlexplained.com/2018/11/30/an-overview-of-normalization-methods-in-deep-learning/" target="_blank" rel="noopener">Blog: An Overview of Normalization Methods in Deep Learning</a></p>

        </div>
        
        
        
        
<div class="sharethis-inline-share-buttons"></div>
<script type='text/javascript' src='//platform-api.sharethis.com/js/sharethis.js#property=5d5e5688c60153001277c466&amp;product=inline-share-buttons' async='async'></script>

        
    </div>
</div>





<div class="card card-transparent">
    <div class="level post-navigation is-flex-wrap is-mobile">
        
        <div class="level-start">
            <a class="level level-item has-link-grey  article-nav-prev" href="/2019/10/16/optimization-algorithm-in-deep-learning/">
                <i class="level-item fas fa-chevron-left"></i>
                <span class="level-item">Optimization Algorithm in Deep Learning</span>
            </a>
        </div>
        
        
        <div class="level-end">
            <a class="level level-item has-link-grey  article-nav-next" href="/2019/08/22/hello-world/">
                <span class="level-item">Hello World</span>
                <i class="level-item fas fa-chevron-right"></i>
            </a>
        </div>
        
    </div>
</div>



<div class="card">
    <div class="card-content">
        <h3 class="title is-5 has-text-weight-normal">Comments</h3>
        
<div id="valine-thread" class="content"></div>
<script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
<script src='//unpkg.com/valine/dist/Valine.min.js'></script>
<script>
    new Valine({
        el: '#valine-thread' ,
        notify: false,
        verify: false,
        app_id: '0UMdpjsaIDv3QIm6TvTb5dMg-MdYXbMMI',
        app_key: 'WV1yT5spokAKC90uiItn48tR',
        lang: 'en',
        placeholder: 'Welcome your ideas',
	visitor: 'true'
    });
</script>

    </div>
</div>
</div>
                




<div class="column is-4-tablet is-4-desktop is-3-widescreen  has-order-1 column-left ">
    
        
<div class="card widget">
    <div class="card-content">
        <nav class="level">
            <div class="level-item has-text-centered" style="flex-shrink: 1">
                <div>
                    
                        <img class="image is-128x128 has-mb-6" src="/images/avatar.png" alt="Your name">
                    
                    
                    <p class="is-size-4 is-block">
                        Your name
                    </p>
                    
                    
                    <p class="is-size-6 is-block">
                        Your title
                    </p>
                    
                    
                    <p class="is-size-6 is-flex is-flex-center has-text-grey">
                        <i class="fas fa-map-marker-alt has-mr-7"></i>
                        <span>Your location</span>
                    </p>
                    
                </div>
            </div>
        </nav>
        <nav class="level is-mobile">
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Posts
                    </p>
                    <p class="title has-text-weight-normal">
                        6
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Categories
                    </p>
                    <p class="title has-text-weight-normal">
                        0
                    </p>
                </div>
            </div>
            <div class="level-item has-text-centered is-marginless">
                <div>
                    <p class="heading">
                        Tags
                    </p>
                    <p class="title has-text-weight-normal">
                        0
                    </p>
                </div>
            </div>
        </nav>
        <div class="level">
            <a class="level-item button is-link is-rounded" href="https://github.com/ppoffice" target="_blank">
                Follow</a>
        </div>
        
        
        <div class="level is-mobile">
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Github" href="https://github.com/ppoffice">
                
                <i class="fab fa-github"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Facebook" href="https://facebook.com">
                
                <i class="fab fa-facebook"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Twitter" href="https://twitter.com">
                
                <i class="fab fa-twitter"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="Dribbble" href="https://dribbble.com">
                
                <i class="fab fa-dribbble"></i>
                
            </a>
            
            <a class="level-item button is-white is-marginless" target="_blank"
                title="RSS" href="/">
                
                <i class="fas fa-rss"></i>
                
            </a>
            
        </div>
        
    </div>
</div>
    
        
    
        
<div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Categories
            </h3>
            <ul class="menu-list">
            
            </ul>
        </div>
    </div>
</div>
    
        
    
    
        <div class="column-right-shadow  ">
        
            
<div class="card widget">
    <div class="card-content">
        <h3 class="menu-label">
            Recent
        </h3>
        
        <article class="media">
            
            <a href="/2019/10/21/google-cloud-for-deep-learning-part-2/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Google Cloud for Deep Learning - Part 2">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-21T16:00:00.000Z">2019-10-22</time></div>
                    <a href="/2019/10/21/google-cloud-for-deep-learning-part-2/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Google Cloud for Deep Learning - Part 2</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/10/17/google-cloud-for-deep-learning-part-1/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Google Cloud for Deep Learning - Part 1">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-17T16:00:00.000Z">2019-10-18</time></div>
                    <a href="/2019/10/17/google-cloud-for-deep-learning-part-1/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Google Cloud for Deep Learning - Part 1</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/10/17/Docker/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-17T07:51:39.554Z">2019-10-17</time></div>
                    <a href="/2019/10/17/Docker/" class="title has-link-black-ter is-size-6 has-text-weight-normal"></a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/10/16/optimization-algorithm-in-deep-learning/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Optimization Algorithm in Deep Learning">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-16T16:00:00.000Z">2019-10-17</time></div>
                    <a href="/2019/10/16/optimization-algorithm-in-deep-learning/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Optimization Algorithm in Deep Learning</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
        <article class="media">
            
            <a href="/2019/10/14/normalization-in-deep-learning/" class="media-left">
                <p class="image is-64x64">
                    <img class="thumbnail" src="/images/thumbnail.svg" alt="Normalization in Deep Learning">
                </p>
            </a>
            
            <div class="media-content">
                <div class="content">
                    <div><time class="has-text-grey is-size-7 is-uppercase" datetime="2019-10-14T16:00:00.000Z">2019-10-15</time></div>
                    <a href="/2019/10/14/normalization-in-deep-learning/" class="title has-link-black-ter is-size-6 has-text-weight-normal">Normalization in Deep Learning</a>
                    <p class="is-size-7 is-uppercase">
                        
                    </p>
                </div>
            </div>
        </article>
        
    </div>
</div>

        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
        <h3 class="menu-label">
            Archives
        </h3>
        <ul class="menu-list">
        
        <li>
            <a class="level is-marginless" href="/archives/2019/10/">
                <span class="level-start">
                    <span class="level-item">October 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">5</span>
                </span>
            </a>
        </li>
        
        <li>
            <a class="level is-marginless" href="/archives/2019/08/">
                <span class="level-start">
                    <span class="level-item">August 2019</span>
                </span>
                <span class="level-end">
                    <span class="level-item tag">1</span>
                </span>
            </a>
        </li>
        
        </ul>
        </div>
    </div>
</div>
        
            <div class="card widget">
    <div class="card-content">
        <div class="menu">
            <h3 class="menu-label">
                Tags
            </h3>
            <div class="field is-grouped is-grouped-multiline">
                
            </div>
        </div>
    </div>
</div>
        
        </div>
    
</div>

                
            </div>
        </div>
    </section>
    <footer class="footer">
    <div class="container">
        <div class="level">
            <div class="level-start has-text-centered-mobile">
                <a class="footer-logo is-block has-mb-6" href="/">
                
                    <img src="/images/logo.svg" alt="Normalization in Deep Learning" height="28">
                
                </a>
                <p class="is-size-7">
                &copy; 2019 Shengzhao Xia&nbsp;
                Powered by <a href="https://hexo.io/" target="_blank">Hexo</a> & <a
                        href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank">Icarus</a>
                
                <br>
                <span id="busuanzi_container_site_pv" class="theme-info">
                Visited by <span id="busuanzi_value_site_uv">0</span> users
                </span>
                <span id="busuanzi_container_site_uv" class="theme-info">
                <span id="busuanzi_value_site_pv">0</span> times
                </span>
                
                </p>
            </div>
            <div class="level-end">
            
                <div class="field has-addons is-flex-center-mobile has-mt-5-mobile is-flex-wrap is-flex-middle">
                
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Creative Commons" href="https://creativecommons.org/">
                        
                        <i class="fab fa-creative-commons"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/">
                        
                        <i class="fab fa-creative-commons-by"></i>
                        
                    </a>
                </p>
                
                <p class="control">
                    <a class="button is-white is-large" target="_blank" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus">
                        
                        <i class="fab fa-github"></i>
                        
                    </a>
                </p>
                
                </div>
            
            </div>
        </div>
    </div>
</footer>

    <script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script>
<script>moment.locale("en");</script>

<script>
var IcarusThemeSettings = {
    article: {
        highlight: {
            clipboard: true,
            fold: 'unfolded'
        }
    }
};
</script>


    <script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script>



    
    
    
    <script src="/js/animation.js"></script>
    

    
    
    
    <script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script>
    <script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script>
    <script src="/js/gallery.js" defer></script>
    

    
    

<div id="outdated">
    <h6>Your browser is out-of-date!</h6>
    <p>Update your browser to view this website correctly. <a id="btnUpdateBrowser" href="http://outdatedbrowser.com/">Update
            my browser now </a></p>
    <p class="last"><a href="#" id="btnCloseUpdateBrowser" title="Close">&times;</a></p>
</div>
<script src="https://cdn.jsdelivr.net/npm/outdatedbrowser@1.1.5/outdatedbrowser/outdatedbrowser.min.js" defer></script>
<script>
    document.addEventListener("DOMContentLoaded", function () {
        outdatedBrowser({
            bgColor: '#f25648',
            color: '#ffffff',
            lowerThan: 'flex'
        });
    });
</script>


    
    
<script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script>
<script>
document.addEventListener('DOMContentLoaded', function () {
    MathJax.Hub.Config({
        'HTML-CSS': {
            matchFontHeight: false
        },
        SVG: {
            matchFontHeight: false
        },
        CommonHTML: {
            matchFontHeight: false
        },
        tex2jax: {
            inlineMath: [
                ['$','$'],
                ['\\(','\\)']
            ]
        }
    });
});
</script>

    
    

<a id="back-to-top" title="Back to Top" href="javascript:;">
    <i class="fas fa-chevron-up"></i>
</a>
<script src="/js/back-to-top.js" defer></script>


    
    

    
    
    
    

    
    
    
    
    

    


<script src="/js/main.js" defer></script>

    
    <div class="searchbox ins-search">
    <div class="searchbox-container ins-search-container">
        <div class="searchbox-input-wrapper">
            <input type="text" class="searchbox-input ins-search-input" placeholder="Type something..." />
            <span class="searchbox-close ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="searchbox-result-wrapper ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script>
    (function (window) {
        var INSIGHT_CONFIG = {
            TRANSLATION: {
                POSTS: 'Posts',
                PAGES: 'Pages',
                CATEGORIES: 'Categories',
                TAGS: 'Tags',
                UNTITLED: '(Untitled)',
            },
            CONTENT_URL: '/content.json',
        };
        window.INSIGHT_CONFIG = INSIGHT_CONFIG;
    })(window);
</script>
<script src="/js/insight.js" defer></script>
<link rel="stylesheet" href="/css/search.css">
<link rel="stylesheet" href="/css/insight.css">
    
</body>
</html>